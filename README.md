# Apache Airflow - Local and Cloud Deployment

## üöÄ Overview

Este reposit√≥rio fornece uma solu√ß√£o completa para implanta√ß√£o do **Apache Airflow** em dois ambientes:
1. **Ambiente Local**: Para testes e compreens√£o de como o Airflow funciona.
2. **Ambiente na Nuvem (AWS)**: Sugest√£o de uma arquitetura escal√°vel e segura utilizando servi√ßos gerenciados da AWS como **MWAA**, **RDS**, **Elasticache(Redis)** e **S3**.

## üìö Inten√ß√£o do Projeto

Este projeto foi criado para demonstrar minhas habilidades e conhecimentos como SRE e para responder a um teste t√©cnico "dre-3-test".
[Exponho aqui](/dev_files/Projeto_Data_Reliability_Engineer_Teste_Tecnico_AudsonYuriFRozendo.pdf) a documenta√ß√£o detalhada em resposta ao desafio.

Aproveito para oferecer uma base s√≥lida para **entusiastas de DevOps** e **profissionais de SRE** aprenderem sobre orquestra√ß√£o de workflows no Airflow em um ambiente local antes de migrar para a nuvem. 

---

## ‚ú® Frase de Efeito

_"Estude, teste, e colabore! A transforma√ß√£o est√° no aprendizado e na pr√°tica."_  

---

## üìÇ Componentes Envolvidos

1. **Ambiente Local**: Configura√ß√£o do Apache Airflow utilizando Docker e Docker Compose.
2. **Ambiente Cloud (AWS)**: Arquitetura sugerida utilizando **AWS MWAA**, **RDS (Postgres)**, **Elasticache (Redis)** e **S3**.

---

## üõ†Ô∏è Ambiente Local - Instala√ß√£o

### 1. Pr√©-requisitos

Certifique-se de ter as seguintes ferramentas instaladas:
- **Docker**: Para criar containers localmente.
- **Docker Compose**: Para orquestrar a infraestrutura localmente.

### 2. Configura√ß√£o do Ambiente Local

Clone este reposit√≥rio e siga os passos abaixo para configurar o ambiente local:

```bash
git clone https://github.com/audsonyuri/apacheairflow_infra.git
cd apacheairflow_infra
```

### 3. Configura√ß√£o de Diret√≥rios e Permiss√µes

No host que executa a orquestra√ß√£o do Airflow, √© necess√°rio ajustar os direitos de acesso nos diret√≥rios **logs**, **dags** e **plugins**, que s√£o bindados pelo Docker. Isso garante que o Airflow (executando com o usu√°rio UID e GID 50000) tenha permiss√µes plenas de leitura e escrita nesses diret√≥rios.

Estando no diret√≥rio raiz do projeto, execute os comandos abaixo:

```bash
mkdir logs dags plugins
sudo chown -R 50000:50000 ./logs ./dags ./plugins
```

Isso garante que o Airflow tenha as permiss√µes adequadas para gerenciar esses diret√≥rios.

### 4. Executando o Airflow Localmente

Com a estrutura configurada, voc√™ pode iniciar os servi√ßos do Airflow:

```bash
docker-compose up -d
```

Ap√≥s a execu√ß√£o, o Airflow estar√° dispon√≠vel no navegador em `http://localhost:8080`.

### 5. Acessando o Ambiente

Abra o navegador e acesse o endere√ßo [http://localhost:8080](http://localhost:8080) para interagir com o Airflow local. Este ambiente √© ideal para testes e entendimento da execu√ß√£o de DAGs, sem custos de infraestrutura cloud.

### 6. Diagrama de Arquitetura e Fluxo de uso

[Componentes da arquitetura:](/dev_files/airflow-components.png)


[Fluxo comum de uso:](/dev_files/airflow-sequence.png)

---

## üö¶ Health Checks

Para garantir a alta disponibilidade e o monitoramento cont√≠nuo dos servi√ßos, health checks foram configurados para os principais componentes.

- **Postgres**:
  ```yaml
  test: ["CMD", "pg_isready", "-U", "airflow"]
  interval: 5s
  retries: 5
  ```

- **Redis**:
  ```yaml
  test: ["CMD", "redis-cli", "ping"]
  interval: 5s
  timeout: 30s
  retries: 50
  ```

- **Airflow Webserver**:
  ```yaml
  test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
  interval: 10s
  timeout: 10s
  retries: 5
  ```

---

## ‚òÅÔ∏è Sugest√£o de Ambiente Cloud (AWS)

### Vis√£o Geral

Ap√≥s entender o funcionamento do Airflow em um ambiente local, a migra√ß√£o para um ambiente cloud oferece escalabilidade, alta disponibilidade e integra√ß√£o com servi√ßos gerenciados. Abaixo, sugiro uma arquitetura cloud utilizando **AWS** para produ√ß√£o.


### Componentes:

1. **IAM**: Controle de acesso com pol√≠ticas espec√≠ficas para **RDS**, **Elasticache**, **S3** e **MWAA**.
2. **VPC**: Isolamento de rede com subnets p√∫blicas e privadas, controladas por **Security Groups**.
3. **RDS (Postgres)**: Banco de dados para armazenamento de metadados, configurado com backups autom√°ticos.
4. **Elasticache (Redis)**: Cache utilizado como broker do CeleryExecutor.
5. **S3**: Buckets para armazenamento de **DAGs**, **Logs**, e **Artefatos**.
6. **AWS MWAA**: Servi√ßo gerenciado de Airflow, escal√°vel e integrado com outros servi√ßos da AWS.

### Arquitetura Sugerida

Abaixo est√° um diagrama sugerido para a arquitetura na AWS:

![AWS Architecture](/dev_files/AWS_Simple_Architecture.png)

### Descri√ß√£o dos Componentes

- **Subnets Privadas**: Cont√™m o **RDS (Postgres)** e o **Elasticache (Redis)**, garantindo comunica√ß√£o segura entre os componentes.
- **Subnets P√∫blicas**: Cont√™m o **MWAA** e o **S3** para o armazenamento de arquivos e logs.
- **NAT Gateway**: Permite que os recursos privados acessem a internet sem exposi√ß√£o direta.
- **Security Groups**: Controlam o tr√°fego entre os servi√ßos internos da AWS e o ambiente externo.


## üéì Incentivo ao Estudo

Este projeto oferece uma oportunidade para quem deseja aprender a orquestrar workflows com o **Apache Airflow**, primeiro em um ambiente local e, posteriormente, migrando para a nuvem da AWS. A pr√°tica local ajuda a entender o funcionamento do Airflow antes de escalar para um ambiente mais complexo como a AWS.

---

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir **issues** ou enviar **pull requests**. A colabora√ß√£o √© a chave para o sucesso na comunidade DevOps e SRE.

---

## üìú Licen√ßa

Este projeto est√° licenciado sob os termos do [MIT License](LICENSE).

---